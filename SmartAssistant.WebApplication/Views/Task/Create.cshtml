@using SmartAssistant.Shared.Models.Task
@model TaskCreateModel

<div class="container mt-5">
    <h2 class="display-6 mb-4 text-primary">Create New Task</h2>

    <!-- Regular form for manual input -->
    <form asp-action="Create">
        <div class="card p-4 mb-5 bg-dark text-light">
            <div class="form-group mb-3">
                <label asp-for="Description" class="form-label fw-bold"></label>
                <input asp-for="Description" class="form-control" />
                <span asp-validation-for="Description" class="text-danger"></span>
            </div>
            <div class="form-group mb-3">
                <label asp-for="DueDate" class="form-label fw-bold"></label>
                <input asp-for="DueDate" type="datetime-local" class="form-control" />
                <span asp-validation-for="DueDate" class="text-danger"></span>
            </div>
            <div class="form-group mb-3">
                <label asp-for="EstimatedTimeToComplete" class="form-label fw-bold"></label>
                <input asp-for="EstimatedTimeToComplete" class="form-control" />
                <span asp-validation-for="EstimatedTimeToComplete" class="text-danger"></span>
            </div>
            <div class="form-group mb-3">
                <label asp-for="Priority" class="form-label fw-bold"></label>
                <select asp-for="Priority" class="form-control" asp-items="Html.GetEnumSelectList<PriorityLevel>()"></select>
                <span asp-validation-for="Priority" class="text-danger"></span>
            </div>
            <button type="submit" class="btn btn-success w-100 fw-bold">Create</button>
        </div>
    </form>

    <!-- Voice Input Section -->
    <div class="card p-4 bg-dark text-light">
        <h3 class="text-primary mb-3">Or use your voice</h3>
        <p id="voiceStepMessage" class="text-info">Say the task description</p>
        <div class="d-flex gap-2">
            <button id="startRecording" onclick="startRecording()" class="btn btn-primary flex-grow-1 fw-bold">Start Recording</button>
            <button id="stopRecording" onclick="stopRecording()" class="btn btn-danger flex-grow-1 fw-bold" disabled>Stop Recording</button>
        </div>
    </div>

    <a asp-action="Index" class="btn btn-secondary mt-4 fw-bold">Back to List</a>
</div>

<!-- Include Recorder.js -->
<script src="~/js/recorder.js"></script>
<script>
    let recorder, audioBlob;
    let currentField = "Description"; // Initialize the field as 'Description' for the first step

    const steps = {
        "Description": "Say the task description",
        "DueDate": "Say the due date",
        "EstimatedTimeToComplete": "Say the estimated time to complete",
        "Priority": "Say the priority (Low, Medium, High)"
    };

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();

            // Initialize the recorder with the audio context
            const input = audioContext.createMediaStreamSource(stream);
            recorder = new Recorder(input, {
                numChannels: 1, // Use mono channel
                sampleRate: 16000 // Set sample rate to match Google's expected format
            });

            recorder.record();
            document.getElementById('stopRecording').disabled = false;
            document.getElementById('startRecording').disabled = true;
        } catch (err) {
            alert("Microphone access denied or not available.");
        }
    }

    function stopRecording() {
        recorder.stop();

        recorder.exportWAV((blob) => {
            audioBlob = blob;
            sendVoiceInput(); // Automatically send the audio after recording stops
        });

        document.getElementById('stopRecording').disabled = true;
        document.getElementById('startRecording').disabled = false;
    }

    async function sendVoiceInput() {
        if (!audioBlob) {
            alert("Please record your voice before sending.");
            return;
        }

        const formData = new FormData();
        formData.append("audioFile", audioBlob, "audio.wav"); // Append the audioBlob correctly to FormData
        formData.append("field", currentField);

        try {
            const response = await fetch(`/Task/VoiceInput`, {
                method: 'POST',
                body: formData
            });

            const result = await response.json();

            if (result.success) {
                alert(result.message);
                window.location.href = "/Task/Index"; // Task created
            } else if (result.nextStep) {
                currentField = result.nextStep; // Move to the next step
                document.getElementById('voiceStepMessage').innerText = steps[currentField];
                alert(result.message);
            } else if (result.error) {
                alert(result.error);
            }
        } catch (err) {
            alert("An error occurred while sending the audio. Please try again.");
        }
    }
</script>
